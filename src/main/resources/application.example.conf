akka {
  loglevel = info
  log-dead-letters = 10
  log-dead-letters-during-shutdown = off
  loggers = [de.heikoseeberger.akkalog4j.Log4jLogger]
  logging-filter = de.heikoseeberger.akkalog4j.Log4jLoggingFilter

  actor {
    warn-about-java-serializer-usage = off
  }

}

mlconfig {
  http-service {
    address             = "0.0.0.0"
    port                = 8283
    self-timeout        = 20000 ms
  }

  fs {
    target = "s3"
    ratings-format = "com.databricks.spark.csv"
    load-last-on-startup = true
  }

  aws {
    location = "s3n://mys3bucket/" #S3 Bucket or a HDFS/FileSystem Path
    access-key-id = "AKIAJKXDHJ6VWOCIELMA" #Access Key for Hadoop Config (s3)
    secret-access-key = "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" #Secret Access Key for Hadoop Config (s3)
  }

  spark {
    default-master = "local[*]"
    port = 4040
    app-name = "ALSTrainer"
    executor-memory = "4G"
    jar = "/Users/xxx/Developer/akka-lift-ml/target/scala-2.11/akkaliftml_2.11-0.1-SNAPSHOT.jar" #right now you must run sbt package to get a jar - set the location of the jar here, because remote spark needs a driver program
  }
}
